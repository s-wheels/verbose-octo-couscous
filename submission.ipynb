{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/lightonai/RITA_s/resolve/main/config.json from cache at /Users/maia/.cache/huggingface/transformers/36175bb600af61a7b34fc92d3e2511016a2ffce591c699fa57e43827a2751720.062cec24332a9b831bfb86a7aca88f74a7cf234dd8ea182800473c491780b606\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "loading configuration file https://huggingface.co/lightonai/RITA_s/resolve/main/config.json from cache at /Users/maia/.cache/huggingface/transformers/36175bb600af61a7b34fc92d3e2511016a2ffce591c699fa57e43827a2751720.062cec24332a9b831bfb86a7aca88f74a7cf234dd8ea182800473c491780b606\n",
      "Model config RITAConfig {\n",
      "  \"_name_or_path\": \"lightonai/RITA_s\",\n",
      "  \"architectures\": [\n",
      "    \"RITAModelForCausalLM\"\n",
      "  ],\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"rita_configuration.RITAConfig\",\n",
      "    \"AutoModel\": \"rita_modeling.RITAModel\",\n",
      "    \"AutoModelForCausalLM\": \"rita_modeling.RITAModelForCausalLM\",\n",
      "    \"AutoModelForSequenceClassification\": \"rita_modeling.RITAModelForSequenceClassification\"\n",
      "  },\n",
      "  \"d_feedforward\": 3072,\n",
      "  \"d_model\": 768,\n",
      "  \"dropout\": 0.0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"max_seq_len\": 1024,\n",
      "  \"model_type\": \"rita\",\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"vocab_size\": 26\n",
      "}\n",
      "\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "loading weights file https://huggingface.co/lightonai/RITA_s/resolve/main/pytorch_model.bin from cache at /Users/maia/.cache/huggingface/transformers/cc5fb8338a40384249a432ed2cae6d2cdea3d9d639102a9308d487d283046059.90b045291d01a3ecd1e7e5b034d1daa7b5442f568cd6eb670f4c4e7c522c348b\n",
      "Some weights of the model checkpoint at lightonai/RITA_s were not used when initializing RITAModelForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing RITAModelForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RITAModelForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RITAModelForSequenceClassification were not initialized from the model checkpoint at lightonai/RITA_s and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading file https://huggingface.co/lightonai/RITA_s/resolve/main/tokenizer.json from cache at /Users/maia/.cache/huggingface/transformers/865e13b3e3619bf81de973416c2704f8c603c81b0d98fa1cee0804f76de7abfa.baa7c198887ac13f3cc484561eb339b721df90ee08c24f2fd2e8453a3f24a0e6\n",
      "loading file https://huggingface.co/lightonai/RITA_s/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/lightonai/RITA_s/resolve/main/special_tokens_map.json from cache at /Users/maia/.cache/huggingface/transformers/1a37d8923e326225df60039df95ed996f3d4ab2ee2c03cb023bed0cf8ec2f1fd.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
      "loading file https://huggingface.co/lightonai/RITA_s/resolve/main/tokenizer_config.json from cache at /Users/maia/.cache/huggingface/transformers/5304688f551159b3f4881ed08887e097b633d7ae482796e51b78f7a5b8aeae02.3ede947a2e06d05a228d78128c9a9220dbe2846dc4462f70877e26c82fe3295f\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"lightonai/RITA_s\", trust_remote_code=True, num_labels=27\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lightonai/RITA_s\")\n",
    "\n",
    "tokenizer.pad_token_id = 1\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(raw_data: str = \"Sequences.fasta\", labelled: bool = True) -> pd.DataFrame:\n",
    "    if labelled:\n",
    "        labelled_sequences = [\n",
    "            {\n",
    "                \"ID\": i.id,\n",
    "                \"Group_ID\": i.id.split(\"_\")[0],\n",
    "                \"Number_ID\": i.id.split(\"_\")[1],\n",
    "                \"Sequence Length\": len(i.seq),\n",
    "                \"Sequence\": i.seq,\n",
    "            }\n",
    "            for i in SeqIO.parse(raw_data, \"fasta\")\n",
    "        ]\n",
    "        print(f\"Number of labelled sequences: {len(labelled_sequences)}\")\n",
    "        return pd.DataFrame(labelled_sequences)\n",
    "    else:\n",
    "        pred_sequences = [\n",
    "            {\"ID\": i.id, \"Sequence Length\": len(i.seq), \"Sequence\": i.seq}\n",
    "            for i in SeqIO.parse(raw_data, \"fasta\")\n",
    "        ]\n",
    "        print(f\"Number of pred sequences: {len(pred_sequences)}\")\n",
    "        return pd.DataFrame(pred_sequences)\n",
    "\n",
    "\n",
    "def create_dataset_split(data_df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    # Splitting dataset, any class with <3 instances added to train_df\n",
    "    filtered_df = data_df[data_df[\"Group_ID\"].isin([\"A\", \"B\", \"C\"])]\n",
    "    train_df, eval_df = train_test_split(\n",
    "        filtered_df, shuffle=True, stratify=filtered_df[\"Group_ID\"]\n",
    "    )\n",
    "    train_df = pd.concat(\n",
    "        [train_df, data_df[~data_df[\"Group_ID\"].isin([\"A\", \"B\", \"C\"])]]\n",
    "    )\n",
    "    print(f\"Train Dataset Size: {len(train_df)}, Eval Dataset Size: {len(eval_df)}\")\n",
    "    return train_df, eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labelled sequences: 1000\n",
      "Train Dataset Size: 756, Eval Dataset Size: 244\n",
      "Number of pred sequences: 10\n"
     ]
    }
   ],
   "source": [
    "labelled_df = load_data(\"Sequences.fasta\", labelled=True)\n",
    "train_df, eval_df = create_dataset_split(labelled_df)\n",
    "pred_df = load_data(\"Predictions.fasta\", labelled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids = labelled_df[\"Group_ID\"].unique()\n",
    "group_id_hash = {group_ids[i]: i for i in range(len(group_ids))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_df: pd.DataFrame,\n",
    "        tokenizer,\n",
    "        group_id_hash: dict,\n",
    "        mode: str = \"train\",\n",
    "        labelled: bool = True,\n",
    "    ):\n",
    "        self.data_df = data_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.group_id_hash = group_id_hash\n",
    "        self.mode = mode\n",
    "        self.labelled = labelled\n",
    "        self.max_sequence_length = self.data_df[\"Sequence Length\"].max()\n",
    "        self.mean_sequence_length = self.data_df[\"Sequence Length\"].mean()\n",
    "        self._preprocess()\n",
    "\n",
    "    def summarise_data(self, save_path: str = None) -> None:\n",
    "        if self.labelled:\n",
    "            print(self.data_df[\"Group_ID\"].value_counts())\n",
    "        print(f\"Mean Sequence Length: {self.mean_sequence_length}\")\n",
    "        print(f\"Max Sequence Length: {self.max_sequence_length}\")\n",
    "        if self.labelled:\n",
    "            print(f'Number of Protein Groups: {self.data_df[\"Group_ID\"].nunique()}')\n",
    "        sns.histplot(self.data_df[\"Sequence Length\"])\n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "\n",
    "    def _preprocess_function(self, sample):\n",
    "        return self.tokenizer(\n",
    "            str(sample),\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_sequence_length,\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "    def _preprocess(self):\n",
    "        self.data_df[\"tokens\"] = self.data_df[\"Sequence\"].apply(\n",
    "            self._preprocess_function\n",
    "        )\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        sample = self.data_df.iloc[idx]\n",
    "        tokens = sample[\"tokens\"]\n",
    "\n",
    "        if self.labelled:\n",
    "            label = torch.LongTensor([self.group_id_hash[sample[\"Group_ID\"]]])\n",
    "            return {\"label\": label, **tokens}\n",
    "        else:\n",
    "            return {\"id\": sample[\"ID\"], **tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ProteinDataset(\n",
    "    data_df=train_df,\n",
    "    tokenizer=tokenizer,\n",
    "    group_id_hash=group_id_hash,\n",
    "    mode=\"train\",\n",
    "    labelled=True,\n",
    ")\n",
    "eval_dataset = ProteinDataset(\n",
    "    data_df=eval_df,\n",
    "    tokenizer=tokenizer,\n",
    "    group_id_hash=group_id_hash,\n",
    "    mode=\"eval\",\n",
    "    labelled=True,\n",
    ")\n",
    "pred_dataset = ProteinDataset(\n",
    "    data_df=pred_df,\n",
    "    tokenizer=tokenizer,\n",
    "    group_id_hash=group_id_hash,\n",
    "    mode=\"pred\",\n",
    "    labelled=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "### Protein Groups\n",
    "\n",
    "| Protein Group   |      Sequences      |\n",
    "|----------|:-------------:|\n",
    "| A |  683 |\n",
    "| B |  193 |\n",
    "| C | 99 |\n",
    "| Other (single instances) | 22 |\n",
    "\n",
    "\n",
    "### Sequences\n",
    "\n",
    "#### Labelled\n",
    "- Mean sequence length: 220.426\n",
    "- Max sequence length: 422 (<512 so viable as pretrained transformer input)\n",
    "\n",
    "#### Prediction\n",
    "- Mean: 183.2\n",
    "- Max: 277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Sequence Length: 183.2\n",
      "Max Sequence Length: 277\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_dataset.summarise_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    171\n",
      "C     48\n",
      "B     25\n",
      "Name: Group_ID, dtype: int64\n",
      "Mean Sequence Length: 222.11065573770492\n",
      "Max Sequence Length: 404\n",
      "Number of Protein Groups: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset.summarise_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A        512\n",
      "C        145\n",
      "B         74\n",
      "P          2\n",
      "PT         1\n",
      "CE         1\n",
      "CC         1\n",
      "L          1\n",
      "D          1\n",
      "HHHH       1\n",
      "U          1\n",
      "AA         1\n",
      "F          1\n",
      "G          1\n",
      "ttttt      1\n",
      "AD         1\n",
      "ADD        1\n",
      "M          1\n",
      "II         1\n",
      "LL         1\n",
      "A)         1\n",
      "A***8      1\n",
      "AC         1\n",
      "AV         1\n",
      "T          1\n",
      "IA         1\n",
      "O          1\n",
      "Name: Group_ID, dtype: int64\n",
      "Mean Sequence Length: 219.88227513227514\n",
      "Max Sequence Length: 422\n",
      "Number of Protein Groups: 27\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset.summarise_data(save_path=\"results/train_sequence_length.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maia/miniforge3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 756\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a80ce01358423ab4471e9dea2b6c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3039.8695, 'train_samples_per_second': 0.497, 'train_steps_per_second': 0.063, 'train_loss': 0.5405931974712171, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=190, training_loss=0.5405931974712171, metrics={'train_runtime': 3039.8695, 'train_samples_per_second': 0.497, 'train_steps_per_second': 0.063, 'train_loss': 0.5405931974712171, 'epoch': 2.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"results/trained_rita.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RITAModelForSequenceClassification(\n",
       "  (transformer): RITAModel(\n",
       "    (embedding): Embedding(26, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): SelfAttention(\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (rotary_embedding): RotaryEmbedding()\n",
       "        )\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): RITAGELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (self_attention): SelfAttention(\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (rotary_embedding): RotaryEmbedding()\n",
       "        )\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): RITAGELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (self_attention): SelfAttention(\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (rotary_embedding): RotaryEmbedding()\n",
       "        )\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): RITAGELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (self_attention): SelfAttention(\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (rotary_embedding): RotaryEmbedding()\n",
       "        )\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): RITAGELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (self_attention): SelfAttention(\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (rotary_embedding): RotaryEmbedding()\n",
       "        )\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): RITAGELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (self_attention): SelfAttention(\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (rotary_embedding): RotaryEmbedding()\n",
       "        )\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): RITAGELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (self_attention): SelfAttention(\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (rotary_embedding): RotaryEmbedding()\n",
       "        )\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): RITAGELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (self_attention): SelfAttention(\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (rotary_embedding): RotaryEmbedding()\n",
       "        )\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): RITAGELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (self_attention): SelfAttention(\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (rotary_embedding): RotaryEmbedding()\n",
       "        )\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): RITAGELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (self_attention): SelfAttention(\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (rotary_embedding): RotaryEmbedding()\n",
       "        )\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): RITAGELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (self_attention): SelfAttention(\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (rotary_embedding): RotaryEmbedding()\n",
       "        )\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): RITAGELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (self_attention): SelfAttention(\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "          (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (rotary_embedding): RotaryEmbedding()\n",
       "        )\n",
       "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): RITAGELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=27, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"results/trained_rita.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/kmj6kw8523x6kfszxm3hmxgm0000gn/T/ipykernel_79295/1044897441.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = nn.functional.softmax(output.logits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | Sample: C, Prediction: C\n",
      "1 | Sample: A, Prediction: A\n",
      "2 | Sample: B, Prediction: B\n",
      "3 | Sample: C, Prediction: C\n",
      "4 | Sample: A, Prediction: A\n",
      "5 | Sample: B, Prediction: C\n",
      "6 | Sample: B, Prediction: B\n",
      "7 | Sample: A, Prediction: A\n",
      "8 | Sample: A, Prediction: A\n",
      "9 | Sample: C, Prediction: C\n",
      "10 | Sample: A, Prediction: A\n",
      "11 | Sample: A, Prediction: A\n",
      "12 | Sample: C, Prediction: C\n",
      "13 | Sample: A, Prediction: A\n",
      "14 | Sample: C, Prediction: C\n",
      "15 | Sample: C, Prediction: C\n",
      "16 | Sample: A, Prediction: A\n",
      "17 | Sample: A, Prediction: A\n",
      "18 | Sample: B, Prediction: B\n",
      "19 | Sample: A, Prediction: A\n",
      "20 | Sample: A, Prediction: A\n",
      "21 | Sample: C, Prediction: C\n",
      "22 | Sample: A, Prediction: A\n",
      "23 | Sample: A, Prediction: A\n",
      "24 | Sample: C, Prediction: C\n",
      "25 | Sample: A, Prediction: A\n",
      "26 | Sample: C, Prediction: C\n",
      "27 | Sample: A, Prediction: A\n",
      "28 | Sample: A, Prediction: A\n",
      "29 | Sample: A, Prediction: A\n",
      "30 | Sample: B, Prediction: B\n",
      "31 | Sample: C, Prediction: C\n",
      "32 | Sample: A, Prediction: A\n",
      "33 | Sample: B, Prediction: B\n",
      "34 | Sample: A, Prediction: A\n",
      "35 | Sample: C, Prediction: C\n",
      "36 | Sample: A, Prediction: A\n",
      "37 | Sample: A, Prediction: A\n",
      "38 | Sample: A, Prediction: A\n",
      "39 | Sample: A, Prediction: A\n",
      "40 | Sample: A, Prediction: A\n",
      "41 | Sample: A, Prediction: A\n",
      "42 | Sample: A, Prediction: A\n",
      "43 | Sample: A, Prediction: A\n",
      "44 | Sample: C, Prediction: C\n",
      "45 | Sample: A, Prediction: A\n",
      "46 | Sample: A, Prediction: A\n",
      "47 | Sample: A, Prediction: A\n",
      "48 | Sample: A, Prediction: A\n",
      "49 | Sample: A, Prediction: A\n",
      "50 | Sample: A, Prediction: A\n",
      "51 | Sample: A, Prediction: A\n",
      "52 | Sample: A, Prediction: A\n",
      "53 | Sample: C, Prediction: C\n",
      "54 | Sample: A, Prediction: A\n",
      "55 | Sample: A, Prediction: A\n",
      "56 | Sample: A, Prediction: A\n",
      "57 | Sample: A, Prediction: A\n",
      "58 | Sample: A, Prediction: A\n",
      "59 | Sample: A, Prediction: A\n",
      "60 | Sample: B, Prediction: B\n",
      "61 | Sample: C, Prediction: C\n",
      "62 | Sample: A, Prediction: A\n",
      "63 | Sample: A, Prediction: A\n",
      "64 | Sample: A, Prediction: A\n",
      "65 | Sample: A, Prediction: A\n",
      "66 | Sample: A, Prediction: A\n",
      "67 | Sample: A, Prediction: A\n",
      "68 | Sample: A, Prediction: A\n",
      "69 | Sample: A, Prediction: A\n",
      "70 | Sample: A, Prediction: A\n",
      "71 | Sample: A, Prediction: A\n",
      "72 | Sample: A, Prediction: A\n",
      "73 | Sample: C, Prediction: C\n",
      "74 | Sample: B, Prediction: B\n",
      "75 | Sample: C, Prediction: C\n",
      "76 | Sample: C, Prediction: C\n",
      "77 | Sample: A, Prediction: A\n",
      "78 | Sample: A, Prediction: A\n",
      "79 | Sample: A, Prediction: A\n",
      "80 | Sample: A, Prediction: A\n",
      "81 | Sample: A, Prediction: A\n",
      "82 | Sample: A, Prediction: A\n",
      "83 | Sample: A, Prediction: A\n",
      "84 | Sample: A, Prediction: A\n",
      "85 | Sample: C, Prediction: B\n",
      "86 | Sample: A, Prediction: A\n",
      "87 | Sample: C, Prediction: C\n",
      "88 | Sample: B, Prediction: B\n",
      "89 | Sample: A, Prediction: A\n",
      "90 | Sample: A, Prediction: A\n",
      "91 | Sample: A, Prediction: A\n",
      "92 | Sample: C, Prediction: C\n",
      "93 | Sample: A, Prediction: A\n",
      "94 | Sample: A, Prediction: A\n",
      "95 | Sample: A, Prediction: A\n",
      "96 | Sample: B, Prediction: B\n",
      "97 | Sample: A, Prediction: A\n",
      "98 | Sample: A, Prediction: A\n",
      "99 | Sample: A, Prediction: A\n",
      "100 | Sample: A, Prediction: A\n",
      "101 | Sample: A, Prediction: A\n",
      "102 | Sample: A, Prediction: A\n",
      "103 | Sample: A, Prediction: A\n",
      "104 | Sample: A, Prediction: A\n",
      "105 | Sample: A, Prediction: A\n",
      "106 | Sample: A, Prediction: A\n",
      "107 | Sample: B, Prediction: B\n",
      "108 | Sample: A, Prediction: A\n",
      "109 | Sample: B, Prediction: B\n",
      "110 | Sample: A, Prediction: A\n",
      "111 | Sample: B, Prediction: B\n",
      "112 | Sample: A, Prediction: A\n",
      "113 | Sample: A, Prediction: A\n",
      "114 | Sample: A, Prediction: A\n",
      "115 | Sample: B, Prediction: B\n",
      "116 | Sample: A, Prediction: A\n",
      "117 | Sample: A, Prediction: A\n",
      "118 | Sample: C, Prediction: C\n",
      "119 | Sample: A, Prediction: A\n",
      "120 | Sample: A, Prediction: A\n",
      "121 | Sample: C, Prediction: C\n",
      "122 | Sample: B, Prediction: B\n",
      "123 | Sample: A, Prediction: A\n",
      "124 | Sample: A, Prediction: A\n",
      "125 | Sample: A, Prediction: A\n",
      "126 | Sample: A, Prediction: A\n",
      "127 | Sample: A, Prediction: A\n",
      "128 | Sample: B, Prediction: B\n",
      "129 | Sample: B, Prediction: B\n",
      "130 | Sample: A, Prediction: A\n",
      "131 | Sample: C, Prediction: C\n",
      "132 | Sample: C, Prediction: C\n",
      "133 | Sample: A, Prediction: A\n",
      "134 | Sample: A, Prediction: A\n",
      "135 | Sample: C, Prediction: C\n",
      "136 | Sample: A, Prediction: A\n",
      "137 | Sample: A, Prediction: A\n",
      "138 | Sample: A, Prediction: A\n",
      "139 | Sample: A, Prediction: A\n",
      "140 | Sample: A, Prediction: A\n",
      "141 | Sample: A, Prediction: A\n",
      "142 | Sample: A, Prediction: A\n",
      "143 | Sample: A, Prediction: A\n",
      "144 | Sample: A, Prediction: A\n",
      "145 | Sample: A, Prediction: A\n",
      "146 | Sample: A, Prediction: A\n",
      "147 | Sample: A, Prediction: A\n",
      "148 | Sample: B, Prediction: C\n",
      "149 | Sample: A, Prediction: A\n",
      "150 | Sample: A, Prediction: A\n",
      "151 | Sample: C, Prediction: C\n",
      "152 | Sample: A, Prediction: A\n",
      "153 | Sample: A, Prediction: A\n",
      "154 | Sample: A, Prediction: A\n",
      "155 | Sample: A, Prediction: A\n",
      "156 | Sample: A, Prediction: A\n",
      "157 | Sample: C, Prediction: C\n",
      "158 | Sample: A, Prediction: A\n",
      "159 | Sample: A, Prediction: A\n",
      "160 | Sample: C, Prediction: C\n",
      "161 | Sample: A, Prediction: A\n",
      "162 | Sample: A, Prediction: A\n",
      "163 | Sample: C, Prediction: C\n",
      "164 | Sample: A, Prediction: A\n",
      "165 | Sample: A, Prediction: A\n",
      "166 | Sample: A, Prediction: A\n",
      "167 | Sample: A, Prediction: A\n",
      "168 | Sample: C, Prediction: C\n",
      "169 | Sample: A, Prediction: A\n",
      "170 | Sample: C, Prediction: C\n",
      "171 | Sample: A, Prediction: A\n",
      "172 | Sample: A, Prediction: A\n",
      "173 | Sample: A, Prediction: A\n",
      "174 | Sample: C, Prediction: C\n",
      "175 | Sample: A, Prediction: A\n",
      "176 | Sample: A, Prediction: A\n",
      "177 | Sample: A, Prediction: A\n",
      "178 | Sample: A, Prediction: A\n",
      "179 | Sample: C, Prediction: C\n",
      "180 | Sample: C, Prediction: C\n",
      "181 | Sample: B, Prediction: B\n",
      "182 | Sample: A, Prediction: A\n",
      "183 | Sample: C, Prediction: C\n",
      "184 | Sample: C, Prediction: C\n",
      "185 | Sample: A, Prediction: A\n",
      "186 | Sample: C, Prediction: C\n",
      "187 | Sample: A, Prediction: A\n",
      "188 | Sample: A, Prediction: A\n",
      "189 | Sample: B, Prediction: B\n",
      "190 | Sample: A, Prediction: A\n",
      "191 | Sample: A, Prediction: A\n",
      "192 | Sample: A, Prediction: A\n",
      "193 | Sample: A, Prediction: A\n",
      "194 | Sample: A, Prediction: A\n",
      "195 | Sample: A, Prediction: A\n",
      "196 | Sample: C, Prediction: C\n",
      "197 | Sample: C, Prediction: C\n",
      "198 | Sample: A, Prediction: A\n",
      "199 | Sample: B, Prediction: B\n",
      "200 | Sample: A, Prediction: A\n",
      "201 | Sample: A, Prediction: A\n",
      "202 | Sample: A, Prediction: A\n",
      "203 | Sample: A, Prediction: A\n",
      "204 | Sample: A, Prediction: A\n",
      "205 | Sample: C, Prediction: C\n",
      "206 | Sample: A, Prediction: A\n",
      "207 | Sample: B, Prediction: B\n",
      "208 | Sample: A, Prediction: A\n",
      "209 | Sample: C, Prediction: C\n",
      "210 | Sample: B, Prediction: B\n",
      "211 | Sample: A, Prediction: A\n",
      "212 | Sample: C, Prediction: C\n",
      "213 | Sample: A, Prediction: A\n",
      "214 | Sample: C, Prediction: C\n",
      "215 | Sample: B, Prediction: B\n",
      "216 | Sample: A, Prediction: A\n",
      "217 | Sample: C, Prediction: C\n",
      "218 | Sample: B, Prediction: B\n",
      "219 | Sample: A, Prediction: A\n",
      "220 | Sample: A, Prediction: A\n",
      "221 | Sample: A, Prediction: A\n",
      "222 | Sample: A, Prediction: A\n",
      "223 | Sample: A, Prediction: A\n",
      "224 | Sample: A, Prediction: A\n",
      "225 | Sample: A, Prediction: A\n",
      "226 | Sample: A, Prediction: A\n",
      "227 | Sample: C, Prediction: C\n",
      "228 | Sample: A, Prediction: A\n",
      "229 | Sample: A, Prediction: A\n",
      "230 | Sample: A, Prediction: A\n",
      "231 | Sample: A, Prediction: A\n",
      "232 | Sample: A, Prediction: A\n",
      "233 | Sample: A, Prediction: A\n",
      "234 | Sample: C, Prediction: C\n",
      "235 | Sample: A, Prediction: A\n",
      "236 | Sample: A, Prediction: A\n",
      "237 | Sample: A, Prediction: A\n",
      "238 | Sample: A, Prediction: A\n",
      "239 | Sample: A, Prediction: A\n",
      "240 | Sample: C, Prediction: C\n",
      "241 | Sample: A, Prediction: A\n",
      "242 | Sample: C, Prediction: C\n",
      "243 | Sample: A, Prediction: A\n"
     ]
    }
   ],
   "source": [
    "### RUN EVALUATION\n",
    "inv_group_id_hash = {val: key for key, val in group_id_hash.items()}\n",
    "prob_groups = []\n",
    "pred_groups = []\n",
    "for i in range(len(eval_dataset)):\n",
    "    sample = eval_dataset[i]\n",
    "    output = model(torch.reshape(torch.IntTensor(sample[\"input_ids\"]), (1, -1)))\n",
    "    assert output.logits.shape == (1, 27)\n",
    "    probs = nn.functional.softmax(output.logits)\n",
    "    prob_groups.append(probs.tolist()[0])\n",
    "    pred_groups.append(inv_group_id_hash[int(probs.argmax())])\n",
    "    print(\n",
    "        f'{i} | Sample: {inv_group_id_hash[int(sample[\"label\"])]}, Prediction: {pred_groups[-1]}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     241\n",
      "False      3\n",
      "Name: Correct, dtype: int64\n",
      "Accuracy: 0.9877049180327869\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Group_ID</th>\n",
       "      <th>Number_ID</th>\n",
       "      <th>Sequence Length</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Group_ID_Predicted</th>\n",
       "      <th>Predicted_Probabilities</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>B_098</td>\n",
       "      <td>B</td>\n",
       "      <td>098</td>\n",
       "      <td>164</td>\n",
       "      <td>(G, S, G, F, I, I, N, D, D, G, Y, A, V, T, N, ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>C</td>\n",
       "      <td>[0.001110101817175746, 0.00020816574397031218,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>C_157</td>\n",
       "      <td>C</td>\n",
       "      <td>157</td>\n",
       "      <td>192</td>\n",
       "      <td>(G, S, G, F, I, I, S, N, D, G, L, I, V, T, N, ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>B</td>\n",
       "      <td>[0.0007062445511110127, 0.00018561746401246637...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>B_080</td>\n",
       "      <td>B</td>\n",
       "      <td>080</td>\n",
       "      <td>151</td>\n",
       "      <td>(G, T, G, F, Y, I, G, S, S, G, W, L, L, T, N, ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>C</td>\n",
       "      <td>[0.001949576078914106, 0.0002489994221832603, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Group_ID Number_ID  Sequence Length  \\\n",
       "797  B_098        B       098              164   \n",
       "956  C_157        C       157              192   \n",
       "779  B_080        B       080              151   \n",
       "\n",
       "                                              Sequence  \\\n",
       "797  (G, S, G, F, I, I, N, D, D, G, Y, A, V, T, N, ...   \n",
       "956  (G, S, G, F, I, I, S, N, D, G, L, I, V, T, N, ...   \n",
       "779  (G, T, G, F, Y, I, G, S, S, G, W, L, L, T, N, ...   \n",
       "\n",
       "                                          tokens Group_ID_Predicted  \\\n",
       "797  [input_ids, token_type_ids, attention_mask]                  C   \n",
       "956  [input_ids, token_type_ids, attention_mask]                  B   \n",
       "779  [input_ids, token_type_ids, attention_mask]                  C   \n",
       "\n",
       "                               Predicted_Probabilities  Correct  \n",
       "797  [0.001110101817175746, 0.00020816574397031218,...    False  \n",
       "956  [0.0007062445511110127, 0.00018561746401246637...    False  \n",
       "779  [0.001949576078914106, 0.0002489994221832603, ...    False  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Save Evaluation Results and Show Errors\n",
    "eval_dataset.data_df[\"Group_ID_Predicted\"] = pred_groups\n",
    "eval_dataset.data_df[\"Predicted_Probabilities\"] = prob_groups\n",
    "eval_dataset.data_df[\"Correct\"] = (\n",
    "    eval_dataset.data_df[\"Group_ID\"] == eval_dataset.data_df[\"Group_ID_Predicted\"]\n",
    ")\n",
    "print(eval_dataset.data_df[\"Correct\"].value_counts())\n",
    "print(f'Accuracy: {eval_dataset.data_df[\"Correct\"].sum()/len(eval_dataset.data_df)}')\n",
    "eval_dataset.data_df[eval_dataset.data_df[\"Correct\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: C, Accuracy: 0.988, Recall: 0.979, Precision: 0.959, Specificity: 0.990, FPR: 0.010\n",
      "Group: A, Accuracy: 1.000, Recall: 1.000, Precision: 1.000, Specificity: 1.000, FPR: 0.000\n",
      "Group: B, Accuracy: 0.988, Recall: 0.920, Precision: 0.958, Specificity: 0.995, FPR: 0.005\n"
     ]
    }
   ],
   "source": [
    "### Calculate evaluation metrics\n",
    "for group_class in eval_dataset.data_df[\"Group_ID\"].unique():\n",
    "    trues = eval_dataset.data_df[(eval_dataset.data_df[\"Correct\"])]\n",
    "    falses = eval_dataset.data_df[~(eval_dataset.data_df[\"Correct\"])]\n",
    "\n",
    "    tp = len(trues[trues[\"Group_ID\"] == group_class])\n",
    "    fp = len(falses[falses[\"Group_ID_Predicted\"] == group_class])\n",
    "    tn = len(trues[trues[\"Group_ID_Predicted\"] != group_class])\n",
    "    fn = len(falses[falses[\"Group_ID\"] == group_class])\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    specificity = tn / (tn + fp)\n",
    "    fpr = fp / (fp + tn)\n",
    "    print(\n",
    "        f\"Group: {group_class}, Accuracy: {acc:.3f}, Recall: {recall:.3f}, Precision: {precision:.3f}, Specificity: {specificity:.3f}, FPR: {fpr:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sequence Length</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>154</td>\n",
       "      <td>(G, S, G, V, I, V, S, P, E, G, H, V, I, T, N, ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>221</td>\n",
       "      <td>(I, V, N, G, K, I, S, T, L, G, E, Y, P, F, M, ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03</td>\n",
       "      <td>135</td>\n",
       "      <td>(L, V, Y, L, K, S, H, F, N, P, C, V, G, V, L, ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04</td>\n",
       "      <td>277</td>\n",
       "      <td>(G, T, G, F, I, N, D, K, N, N, G, Y, I, I, T, ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05</td>\n",
       "      <td>201</td>\n",
       "      <td>(G, S, A, F, F, I, S, K, D, G, Y, L, L, T, N, ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>06</td>\n",
       "      <td>138</td>\n",
       "      <td>(S, G, F, V, S, A, P, D, Y, V, V, T, N, A, H, ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>07</td>\n",
       "      <td>199</td>\n",
       "      <td>(G, T, G, F, F, I, T, K, D, G, Y, V, L, T, N, ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08</td>\n",
       "      <td>179</td>\n",
       "      <td>(G, S, G, V, I, I, S, K, D, G, Y, I, V, T, N, ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09</td>\n",
       "      <td>136</td>\n",
       "      <td>(G, F, V, V, D, A, E, R, G, Y, I, L, T, N, R, ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>192</td>\n",
       "      <td>(S, G, V, L, V, G, P, H, H, I, L, T, A, A, H, ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Sequence Length                                           Sequence  \\\n",
       "0  01              154  (G, S, G, V, I, V, S, P, E, G, H, V, I, T, N, ...   \n",
       "1  02              221  (I, V, N, G, K, I, S, T, L, G, E, Y, P, F, M, ...   \n",
       "2  03              135  (L, V, Y, L, K, S, H, F, N, P, C, V, G, V, L, ...   \n",
       "3  04              277  (G, T, G, F, I, N, D, K, N, N, G, Y, I, I, T, ...   \n",
       "4  05              201  (G, S, A, F, F, I, S, K, D, G, Y, L, L, T, N, ...   \n",
       "5  06              138  (S, G, F, V, S, A, P, D, Y, V, V, T, N, A, H, ...   \n",
       "6  07              199  (G, T, G, F, F, I, T, K, D, G, Y, V, L, T, N, ...   \n",
       "7  08              179  (G, S, G, V, I, I, S, K, D, G, Y, I, V, T, N, ...   \n",
       "8  09              136  (G, F, V, V, D, A, E, R, G, Y, I, L, T, N, R, ...   \n",
       "9  10              192  (S, G, V, L, V, G, P, H, H, I, L, T, A, A, H, ...   \n",
       "\n",
       "                                        tokens  \n",
       "0  [input_ids, token_type_ids, attention_mask]  \n",
       "1  [input_ids, token_type_ids, attention_mask]  \n",
       "2  [input_ids, token_type_ids, attention_mask]  \n",
       "3  [input_ids, token_type_ids, attention_mask]  \n",
       "4  [input_ids, token_type_ids, attention_mask]  \n",
       "5  [input_ids, token_type_ids, attention_mask]  \n",
       "6  [input_ids, token_type_ids, attention_mask]  \n",
       "7  [input_ids, token_type_ids, attention_mask]  \n",
       "8  [input_ids, token_type_ids, attention_mask]  \n",
       "9  [input_ids, token_type_ids, attention_mask]  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dataset.data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/kmj6kw8523x6kfszxm3hmxgm0000gn/T/ipykernel_79295/4142473098.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = nn.functional.softmax(output.logits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 | Prediction: C\n",
      "02 | Prediction: A\n",
      "03 | Prediction: A\n",
      "04 | Prediction: C\n",
      "05 | Prediction: B\n",
      "06 | Prediction: B\n",
      "07 | Prediction: B\n",
      "08 | Prediction: B\n",
      "09 | Prediction: C\n",
      "10 | Prediction: A\n"
     ]
    }
   ],
   "source": [
    "### Make predictions\n",
    "inv_group_id_hash = {val: key for key, val in group_id_hash.items()}\n",
    "prob_groups = []\n",
    "pred_groups = []\n",
    "for i in range(len(pred_dataset)):\n",
    "    sample = pred_dataset[i]\n",
    "    output = model(torch.reshape(torch.IntTensor(sample[\"input_ids\"]), (1, -1)))\n",
    "    assert output.logits.shape == (1, 27)\n",
    "    probs = nn.functional.softmax(output.logits)\n",
    "    prob_groups.append(\n",
    "        {\n",
    "            key: val.item()\n",
    "            for key, val in zip(list(group_id_hash.keys()), list(probs)[0])\n",
    "        }\n",
    "    )\n",
    "    pred_groups.append(inv_group_id_hash[int(probs.argmax())])\n",
    "    print(f'{sample[\"id\"]} | Prediction: {pred_groups[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset.data_df[\"Group_ID_Predicted\"] = pred_groups\n",
    "pred_dataset.data_df[\"Predicted_Probabilities\"] = prob_groups\n",
    "pred_dataset.data_df.to_csv(\"results/rita_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fc0ea5a1e9e76f4e43521cfbf8502dc34ed22083c8204b9bca502883f1d045c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
