{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/lightonai/RITA_s/resolve/main/config.json from cache at /Users/maia/.cache/huggingface/transformers/36175bb600af61a7b34fc92d3e2511016a2ffce591c699fa57e43827a2751720.062cec24332a9b831bfb86a7aca88f74a7cf234dd8ea182800473c491780b606\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "loading configuration file https://huggingface.co/lightonai/RITA_s/resolve/main/config.json from cache at /Users/maia/.cache/huggingface/transformers/36175bb600af61a7b34fc92d3e2511016a2ffce591c699fa57e43827a2751720.062cec24332a9b831bfb86a7aca88f74a7cf234dd8ea182800473c491780b606\n",
      "Model config RITAConfig {\n",
      "  \"_name_or_path\": \"lightonai/RITA_s\",\n",
      "  \"architectures\": [\n",
      "    \"RITAModelForCausalLM\"\n",
      "  ],\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"rita_configuration.RITAConfig\",\n",
      "    \"AutoModel\": \"rita_modeling.RITAModel\",\n",
      "    \"AutoModelForCausalLM\": \"rita_modeling.RITAModelForCausalLM\",\n",
      "    \"AutoModelForSequenceClassification\": \"rita_modeling.RITAModelForSequenceClassification\"\n",
      "  },\n",
      "  \"d_feedforward\": 3072,\n",
      "  \"d_model\": 768,\n",
      "  \"dropout\": 0.0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"max_seq_len\": 1024,\n",
      "  \"model_type\": \"rita\",\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"vocab_size\": 26\n",
      "}\n",
      "\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "loading weights file https://huggingface.co/lightonai/RITA_s/resolve/main/pytorch_model.bin from cache at /Users/maia/.cache/huggingface/transformers/cc5fb8338a40384249a432ed2cae6d2cdea3d9d639102a9308d487d283046059.90b045291d01a3ecd1e7e5b034d1daa7b5442f568cd6eb670f4c4e7c522c348b\n",
      "All model checkpoint weights were used when initializing RITAModelForCausalLM.\n",
      "\n",
      "All the weights of RITAModelForCausalLM were initialized from the model checkpoint at lightonai/RITA_s.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RITAModelForCausalLM for predictions without further training.\n",
      "loading file https://huggingface.co/lightonai/RITA_s/resolve/main/tokenizer.json from cache at /Users/maia/.cache/huggingface/transformers/865e13b3e3619bf81de973416c2704f8c603c81b0d98fa1cee0804f76de7abfa.baa7c198887ac13f3cc484561eb339b721df90ee08c24f2fd2e8453a3f24a0e6\n",
      "loading file https://huggingface.co/lightonai/RITA_s/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/lightonai/RITA_s/resolve/main/special_tokens_map.json from cache at /Users/maia/.cache/huggingface/transformers/1a37d8923e326225df60039df95ed996f3d4ab2ee2c03cb023bed0cf8ec2f1fd.5cc6e825eb228a7a5cfd27cb4d7151e97a79fb962b31aaf1813aa102e746584b\n",
      "loading file https://huggingface.co/lightonai/RITA_s/resolve/main/tokenizer_config.json from cache at /Users/maia/.cache/huggingface/transformers/5304688f551159b3f4881ed08887e097b633d7ae482796e51b78f7a5b8aeae02.3ede947a2e06d05a228d78128c9a9220dbe2846dc4462f70877e26c82fe3295f\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"lightonai/RITA_s\", trust_remote_code=True, num_labels=27)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lightonai/RITA_s\")\n",
    "tokenizer.pad_token_id = 1\n",
    "\n",
    "model.config.vocab_size = 27\n",
    "\n",
    "# # Tokens for creating the decoder_input_ids from the labels\n",
    "# model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "# model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(raw_data: str = 'Sequences.fasta', labelled: bool = True) -> pd.DataFrame:\n",
    "    if labelled:\n",
    "        labelled_sequences = [{\n",
    "                    'ID' : i.id,\n",
    "                    'Group_ID' : i.id.split('_')[0],\n",
    "                    'Number_ID' : i.id.split('_')[1],\n",
    "                    'Sequence Length' : len(i.seq),\n",
    "                    'Sequence' : i.seq\n",
    "                    }\n",
    "                    for i in SeqIO.parse(raw_data, 'fasta')]\n",
    "        print(f'Number of labelled sequences: {len(labelled_sequences)}')\n",
    "        return pd.DataFrame(labelled_sequences)\n",
    "    else:\n",
    "        pred_sequences = [{'ID' : i.id,\n",
    "                    'Sequence Length' : len(i.seq),\n",
    "                        'Sequence' : i.seq}\n",
    "                        for i in SeqIO.parse(raw_data, 'fasta')]\n",
    "        print(f'Number of pred sequences: {len(pred_sequences)}')\n",
    "        return pd.DataFrame(pred_sequences)\n",
    "\n",
    "def create_dataset_split(data_df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    # Splitting dataset, any class with <3 instances added to train_df\n",
    "    filtered_df = data_df[data_df['Group_ID'].isin(['A','B','C'])]\n",
    "    train_df, eval_df = train_test_split(filtered_df, shuffle=True, stratify=filtered_df['Group_ID'])\n",
    "    train_df = pd.concat([train_df, data_df[~data_df['Group_ID'].isin(['A','B','C'])]])\n",
    "    print(f'Train Dataset Size: {len(train_df)}, Eval Dataset Size: {len(eval_df)}')\n",
    "    return train_df, eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labelled sequences: 1000\n",
      "Train Dataset Size: 756, Eval Dataset Size: 244\n",
      "Number of pred sequences: 10\n"
     ]
    }
   ],
   "source": [
    "labelled_df = load_data('Sequences.fasta', labelled=True)\n",
    "train_df, eval_df = create_dataset_split(labelled_df)\n",
    "pred_df = load_data('Predictions.fasta', labelled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_df: pd.DataFrame, tokenizer,\n",
    "                 mode: str = 'train', labelled: bool = True):\n",
    "        self.data_df = data_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mode = mode        \n",
    "        self.labelled = labelled\n",
    "        self.max_sequence_length = self.data_df[\"Sequence Length\"].max()\n",
    "        self.mean_sequence_length = self.data_df[\"Sequence Length\"].mean()\n",
    "        self.preprocess()\n",
    "\n",
    "    def summarise_data(self) -> None:\n",
    "        if self.labelled:\n",
    "            print(self.data_df['Group_ID'].value_counts())\n",
    "        print(f'Mean Sequence Length: {self.mean_sequence_length}')\n",
    "        print(f'Max Sequence Length: {self.max_sequence_length}')\n",
    "        if self.labelled:\n",
    "            print(f'Number of Protein Groups: {self.data_df[\"Group_ID\"].nunique()}')\n",
    "        sns.histplot(self.data_df['Sequence Length'])\n",
    "        \n",
    "    def _preprocess_function(self, sample):\n",
    "        return self.tokenizer(str(sample), padding='max_length',\n",
    "                              max_length=self.max_sequence_length,\n",
    "                              truncation=True)['input_ids']\n",
    "\n",
    "    def preprocess(self):\n",
    "        self.data_df['input_ids'] = self.data_df['Sequence'].apply(self._preprocess_function)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        sample = self.data_df.iloc[idx]\n",
    "        tokens = self.tokenizer(str(sample['Sequence']), padding='max_length',\n",
    "                                max_length=self.max_sequence_length)\n",
    "\n",
    "        tokens = {key: torch.reshape(torch.IntTensor(item), (-1,1))\n",
    "                  for key, item in tokens.items()}\n",
    "        \n",
    "        # if self.labelled:\n",
    "        #     return {\n",
    "        #             'labels' : sample['Group_ID'],\n",
    "        #             'input_ids' : tokens['input_ids']\n",
    "        #             }\n",
    "        # else:\n",
    "        #     return {\n",
    "        #             'input_ids' : tokens['input_ids']\n",
    "        #             }  \n",
    "\n",
    "        if self.labelled:\n",
    "            return {\n",
    "                    'labels' : sample['Group_ID'],\n",
    "                    **tokens\n",
    "                    }\n",
    "        else:\n",
    "            return {\n",
    "                    **tokens\n",
    "                    }  \n",
    "        # PAD tokens are ignored by the loss function\n",
    "        # labels = [\n",
    "        #     label if label != self.processor.tokenizer.pad_token_id else -100\n",
    "        #     for label in labels\n",
    "        # ]\n",
    "        # if self.labelled:\n",
    "        #     return {'mode' : self.mode,\n",
    "        #             'labels' : sample['Group_ID'],\n",
    "        #             'input_ids' : self.tokenizer(str(sample['Sequence']),\n",
    "        #                                          padding=\"max_length\",\n",
    "        #                                          max_length=self.max_target_length)\n",
    "        #             }\n",
    "        # else:\n",
    "        #     return {'mode' : self.mode,\n",
    "        #             'input_ids' : self.tokenizer(str(sample['Sequence']),\n",
    "        #                                          padding=\"max_length\",\n",
    "        #                                          max_length=self.max_target_length)\n",
    "        #             }       \n",
    "                    \n",
    "        # if self.labelled:\n",
    "        #     return {'mode' : self.mode,\n",
    "        #             'labels' : sample['Group_ID'],\n",
    "        #             'input_ids' : sample['input_ids']}\n",
    "        # else:\n",
    "        #     return {'mode' : self.mode,\n",
    "        #             'input_ids' : sample['input_ids']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ProteinDataset(data_df=train_df, tokenizer=tokenizer, mode='train', labelled=True)\n",
    "eval_dataset = ProteinDataset(data_df=eval_df, tokenizer=tokenizer, mode='eval', labelled=True)\n",
    "pred_dataset = ProteinDataset(data_df=pred_df, tokenizer=tokenizer, mode='pred', labelled=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "### Protein Groups\n",
    "\n",
    "| Protein Group   |      Sequences      |\n",
    "|----------|:-------------:|\n",
    "| A |  683 |\n",
    "| B |  193 |\n",
    "| C | 99 |\n",
    "| Other (single instances) | 22 |\n",
    "\n",
    "\n",
    "### Sequences\n",
    "\n",
    "#### Labelled\n",
    "- Mean sequence length: 220.426\n",
    "- Max sequence length: 422 (<512 so viable as pretrained transformer input)\n",
    "\n",
    "#### Prediction\n",
    "- Mean: 183.2\n",
    "- Max: 277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Sequence Length: 183.2\n",
      "Max Sequence Length: 277\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_dataset.summarise_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    171\n",
      "C     48\n",
      "B     25\n",
      "Name: Group_ID, dtype: int64\n",
      "Mean Sequence Length: 216.1516393442623\n",
      "Max Sequence Length: 371\n",
      "Number of Protein Groups: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset.summarise_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A        512\n",
      "C        145\n",
      "B         74\n",
      "P          2\n",
      "PT         1\n",
      "CE         1\n",
      "CC         1\n",
      "L          1\n",
      "D          1\n",
      "HHHH       1\n",
      "U          1\n",
      "AA         1\n",
      "F          1\n",
      "G          1\n",
      "ttttt      1\n",
      "AD         1\n",
      "ADD        1\n",
      "M          1\n",
      "II         1\n",
      "LL         1\n",
      "A)         1\n",
      "A***8      1\n",
      "AC         1\n",
      "AV         1\n",
      "T          1\n",
      "IA         1\n",
      "O          1\n",
      "Name: Group_ID, dtype: int64\n",
      "Mean Sequence Length: 221.80555555555554\n",
      "Max Sequence Length: 422\n",
      "Number of Protein Groups: 27\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset.summarise_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Selected pretrained model from HuggingFace.\n",
    "\n",
    "Paper is in preprint https://arxiv.org/abs/2205.05789 [1]\n",
    "\n",
    "Small version has 1/3 parameters of the current most popular HuggingFace model.\n",
    "\n",
    "Given time constraints a smaller model is a big pro!\n",
    "\n",
    "[1] RITA: a Study on Scaling Up Generative Protein Sequence Models. Hesslow et al., 2022.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutput(loss=None, logits=tensor([[[-16.6796, -16.6797,  -3.0574,  ..., -16.6796, -16.6796, -16.6794]],\n",
       "\n",
       "        [[-16.6618, -16.6620,  -3.0461,  ..., -16.6618, -16.6619, -16.6617]],\n",
       "\n",
       "        [[-16.6138, -16.6140,  -3.0733,  ..., -16.6138, -16.6138, -16.6136]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-16.5405, -16.5407,  -3.1410,  ..., -16.5406, -16.5406, -16.5404]],\n",
       "\n",
       "        [[-16.4934, -16.4936,  -3.0502,  ..., -16.4935, -16.4935, -16.4933]],\n",
       "\n",
       "        [[-16.2706, -16.2708,  -3.0160,  ..., -16.2707, -16.2707, -16.2705]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), hidden_states=tensor([[[-0.0213,  0.1430, -0.0275,  ..., -0.1657, -0.0290, -0.0518]],\n",
       "\n",
       "        [[-0.0189,  0.1432, -0.0178,  ..., -0.1628, -0.0263, -0.0539]],\n",
       "\n",
       "        [[-0.0155,  0.1426, -0.0254,  ..., -0.1609, -0.0255, -0.0485]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0208,  0.1413, -0.0219,  ..., -0.1990,  0.0070, -0.0576]],\n",
       "\n",
       "        [[-0.0164,  0.1468, -0.0291,  ..., -0.1890, -0.0067, -0.0563]],\n",
       "\n",
       "        [[-0.0124,  0.1422, -0.0207,  ..., -0.1782, -0.0096, -0.0613]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), attentions=None)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test forward pass\n",
    "# model.forward(input_ids=train_dataset[0]['input_ids'],\n",
    "#               token_type_ids=train_dataset[0]['token_type_ids'],\n",
    "#               attention_mask=train_dataset[0]['attention_mask'])\n",
    "model.forward(input_ids=train_dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['labels', 'input_ids'])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maia/miniforge3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 756\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfeab42db80e442692420a7fa42e94ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/maia/Documents/GitHub/professional/job_take_homes/basecamp_research/submission.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maia/Documents/GitHub/professional/job_take_homes/basecamp_research/submission.ipynb#ch0000075?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/transformers/trainer.py:1409\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1406\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1407\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1408\u001b[0m )\n\u001b[0;32m-> 1409\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1410\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1411\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1412\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1413\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1414\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/transformers/trainer.py:1651\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1649\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1650\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1651\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1653\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1654\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1655\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1656\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1657\u001b[0m ):\n\u001b[1;32m   1658\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1659\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/transformers/trainer.py:2345\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2342\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2344\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2345\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2348\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/transformers/trainer.py:2377\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2376\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2377\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2378\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2379\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/lightonai/RITA_s/fced662eadd2b7099a3b92a88365dfc3c98eb3da/rita_modeling.py:312\u001b[0m, in \u001b[0;36mRITAModelForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, causal_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_causal_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    294\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    295\u001b[0m     input_ids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     return_dict\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m \u001b[39m# NOT USED\u001b[39;00m\n\u001b[1;32m    310\u001b[0m     ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor:\n\u001b[0;32m--> 312\u001b[0m     transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m    313\u001b[0m         input_ids,\n\u001b[1;32m    314\u001b[0m         past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    315\u001b[0m         causal_mask\u001b[39m=\u001b[39;49mcausal_mask,\n\u001b[1;32m    316\u001b[0m         attention_mask \u001b[39m=\u001b[39;49m attention_mask,\n\u001b[1;32m    317\u001b[0m         token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m    318\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    319\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    320\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    321\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    322\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    323\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    324\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    325\u001b[0m     )\n\u001b[1;32m    327\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(transformer_outputs\u001b[39m.\u001b[39mhidden_states)\n\u001b[1;32m    328\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/lightonai/RITA_s/fced662eadd2b7099a3b92a88365dfc3c98eb3da/rita_modeling.py:251\u001b[0m, in \u001b[0;36mRITAModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, causal_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_causal_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    249\u001b[0m     causal_mask \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mtriu(torch\u001b[39m.\u001b[39mones(input_ids\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), input_ids\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mto(input_ids\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    250\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 251\u001b[0m     x \u001b[39m=\u001b[39m layer(x, causal_mask\u001b[39m=\u001b[39;49mcausal_mask, attention_mask\u001b[39m=\u001b[39;49mattention_mask)\n\u001b[1;32m    252\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_norm(x)  \u001b[39m# N x L x D\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m BaseModelOutput(\n\u001b[1;32m    255\u001b[0m     hidden_states\u001b[39m=\u001b[39mx,\n\u001b[1;32m    256\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/lightonai/RITA_s/fced662eadd2b7099a3b92a88365dfc3c98eb3da/rita_modeling.py:204\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[0;34m(self, x, causal_mask, attention_mask)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    199\u001b[0m     x: torch\u001b[39m.\u001b[39mFloatTensor,\n\u001b[1;32m    200\u001b[0m     causal_mask: torch\u001b[39m.\u001b[39mBoolTensor,\n\u001b[1;32m    201\u001b[0m     attention_mask: Optional[torch\u001b[39m.\u001b[39mBoolTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    202\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor:\n\u001b[1;32m    203\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn_norm(x)\n\u001b[0;32m--> 204\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attention(y, causal_mask\u001b[39m=\u001b[39;49mcausal_mask, attention_mask\u001b[39m=\u001b[39;49mattention_mask)\n\u001b[1;32m    205\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn_dropout(y)\n\u001b[1;32m    207\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_norm(x)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/lightonai/RITA_s/fced662eadd2b7099a3b92a88365dfc3c98eb3da/rita_modeling.py:136\u001b[0m, in \u001b[0;36mSelfAttention.forward\u001b[0;34m(self, x, causal_mask, attention_mask)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    130\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    131\u001b[0m     x,\n\u001b[1;32m    132\u001b[0m     causal_mask: Optional[torch\u001b[39m.\u001b[39mBoolTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    133\u001b[0m     attention_mask: Optional[torch\u001b[39m.\u001b[39mBoolTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    134\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mFloatTensor, torch\u001b[39m.\u001b[39mFloatTensor]:\n\u001b[0;32m--> 136\u001b[0m     N, L, D \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize()  \u001b[39m# Batch_size, Context_size, d_model\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[39m# calculate query, key, values for all heads in batch and move head forward to be the batch dim\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     k \u001b[39m=\u001b[39m (\n\u001b[1;32m    140\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey(x)\u001b[39m.\u001b[39mview(N, L, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, D \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    141\u001b[0m     )  \u001b[39m# (N, nh, L, hs)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Vocab size is the number of integers 0-9\n",
    "model.config.vocab_size = 10\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    output_dir=\"results/\",\n",
    "    logging_steps=2,\n",
    "    save_steps=1000,\n",
    "    num_train_epochs=2,\n",
    "    eval_steps=200,\n",
    ")\n",
    "### HUGGING FACE\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=default_data_collator,\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fc0ea5a1e9e76f4e43521cfbf8502dc34ed22083c8204b9bca502883f1d045c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
